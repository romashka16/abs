import os
import sys
import shutil
import subprocess
import whisper
import torch
from tqdm import tqdm
import ffmpeg
import pysubs2
from moviepy.video.io.VideoFileClip import VideoFileClip
from moviepy.audio.AudioClip import concatenate_audioclips


# ‚îÄ‚îÄ‚îÄ –ö–û–ù–§–ò–ì–£–†–ê–¶–ò–Ø ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ
BASE_FOLDER    = r"C:\Users\–õ–µ–æ–Ω–∏–¥\Desktop\Videos"
TOP_FOLDER = os.path.join(BASE_FOLDER, "top_clips")
SEGMENT_TIME   = 120   # –¥–ª–∏–Ω–∞ —Å–µ–≥–º–µ–Ω—Ç–∞ –≤ —Å–µ–∫—É–Ω–¥–∞—Ö


STACKED_FOLDER   = os.path.join(BASE_FOLDER, "stacked_videos")
AUDIO_FOLDER     = os.path.join(BASE_FOLDER, "audio_wavs")
SUBTITLED_FOLDER = os.path.join(BASE_FOLDER, "subtitled_videos")
SEGMENTS_ROOT    = os.path.join(BASE_FOLDER, "segments")
BOTTOM_FOLDER = os.path.join(BASE_FOLDER, "bottom_clips")


for d in (STACKED_FOLDER, AUDIO_FOLDER, SUBTITLED_FOLDER, SEGMENTS_ROOT,BOTTOM_FOLDER):
    os.makedirs(d, exist_ok=True)
# ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ

def list_top_videos():
    return [os.path.join(TOP_FOLDER, f) for f in sorted(os.listdir(TOP_FOLDER)) if is_video_file(f)]

def check_ffmpeg():
    if shutil.which("ffmpeg") is None:
        print("‚ùå FFmpeg –Ω–µ –Ω–∞–π–¥–µ–Ω –≤ PATH.")
        sys.exit(1)

def is_video_file(fn):
    return fn.lower().endswith(('.mp4','.mkv','.avi','.mov'))

def list_bottom_videos(TOP_VIDEO):
    outs = []
    for fn in sorted(os.listdir(BOTTOM_FOLDER)):
        full = os.path.join(BOTTOM_FOLDER, fn)
        if not os.path.isfile(full) or not is_video_file(fn):
            continue
        # –°—Ä–∞–≤–Ω–∏–≤–∞–µ–º –Ω–æ—Ä–º–∞–ª–∏–∑–æ–≤–∞–Ω–Ω—ã–µ –ø—É—Ç–∏, —á—Ç–æ–±—ã –∏—Å–∫–ª—é—á–∏—Ç—å top
        if os.path.normcase(full) == os.path.normcase(TOP_VIDEO):
            continue
        outs.append(full)
    return outs


import subprocess
import os

def stack_loop_with_fade(bottom, top, out_path, BASE_FOLDER):
    # –ò—Å–ø–æ–ª—å–∑—É–µ–º –∞–±—Å–æ–ª—é—Ç–Ω—ã–µ –ø—É—Ç–∏
    abs_top = os.path.abspath(top)
    abs_bottom = os.path.abspath(bottom)
    abs_out = os.path.abspath(out_path)

    # –ü–æ–ª—É—á–∞–µ–º –¥–ª–∏—Ç–µ–ª—å–Ω–æ—Å—Ç—å –≤–µ—Ä—Ö–Ω–µ–≥–æ –≤–∏–¥–µ–æ —Å –ø–æ–º–æ—â—å—é ffprobe
    try:
        video_info = ffmpeg.probe(abs_top, v='error', select_streams='v:0', show_entries='format=duration')
        duration = float(video_info['format']['duration'])
        print(f"–î–ª–∏—Ç–µ–ª—å–Ω–æ—Å—Ç—å –≤–µ—Ä—Ö–Ω–µ–≥–æ –≤–∏–¥–µ–æ: {duration} —Å–µ–∫—É–Ω–¥.")
    except ffmpeg._run.Error as e:
        print(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ –ø–æ–ª—É—á–µ–Ω–∏–∏ –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–∏ –æ –≤–∏–¥–µ–æ: {e.stderr.decode()}")
        return

    # –°–æ–±–∏—Ä–∞–µ–º –∫–æ–º–∞–Ω–¥—É –¥–ª—è ffmpeg
    cmd = [
        "ffmpeg", "-y",
        "-i", abs_top,
        "-i", abs_bottom,
        "-t", str(duration),
        "-filter_complex",
        "[0:v]scale=1280:360[top];"
        "[1:v]scale=1280:360[bottom];"
        "[top][bottom]vstack=inputs=2[stacked];"
        "[stacked]split=2[main][blur];"
        "[blur]crop=1280:20:0:350,boxblur=5:1[bluredline];"
        "[main][bluredline]overlay=0:350",
        "-c:v", "libx264",
        "-crf", "23",
        "-preset", "medium",
        abs_out
    ]

    print(f"üî® –°—Ç—ç–∫–∞–µ–º —Å –º—è–≥–∫–æ–π –≥—Ä–∞–Ω–∏—Ü–µ–π ‚Üí {abs_out}")

    # –í—ã–ø–æ–ª–Ω—è–µ–º –∫–æ–º–∞–Ω–¥—É
    try:
        result = subprocess.run(cmd, cwd=BASE_FOLDER, capture_output=True, text=True, encoding="utf-8", errors="replace")
        print("STDOUT:\n", result.stdout)
        print("STDERR:\n", result.stderr)

        result.check_returncode()  # –ü—Ä–æ–≤–µ—Ä—è–µ–º, —á—Ç–æ –∫–æ–º–∞–Ω–¥–∞ –ø—Ä–æ—à–ª–∞ —É—Å–ø–µ—à–Ω–æ
    except subprocess.CalledProcessError as e:
        print(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ –≤—ã–ø–æ–ª–Ω–µ–Ω–∏–∏ ffmpeg: {e.stderr}")
        return

    print("–ü—Ä–æ—Ü–µ—Å—Å –∑–∞–≤–µ—Ä—à–µ–Ω —É—Å–ø–µ—à–Ω–æ!")


# def prepare_mfa_corpus(wav_path, text_path, transcript_text):
#     # –°–æ–∑–¥–∞—ë–º plain text —Ñ–∞–π–ª —Å —Ä–∞—Å—à–∏—Ñ—Ä–æ–≤–∫–æ–π –¥–ª—è MFA (–Ω–∞–ø—Ä–∏–º–µ—Ä, text_path.lab)
#     with open(text_path, 'w', encoding='utf-8') as f:
#         f.write(transcript_text)
#
# def run_mfa_align(wav_path, text_path, output_dir):
#     # –í—ã–∑–æ–≤ MFA —Å –∫–æ–º–∞–Ω–¥–æ–π, –Ω–∞–ø—Ä–∏–º–µ—Ä:
#     # mfa align corpus_path dictionary_path output_dir
#     # –ó–¥–µ—Å—å corpus_path - –ø–∞–ø–∫–∞ —Å wav –∏ —Ç–µ–∫—Å—Ç–æ–º
#     # –ü—Ä–∏–º–µ—Ä –∫–æ–º–∞–Ω–¥—ã:
#     cmd = [
#         "mfa", "align",
#         "--clean",
#         "--output_format", "textgrid",
#         "path_to_corpus",
#         "path_to_dictionary",
#         output_dir
#     ]
#     subprocess.run(cmd, check=True)

# def parse_textgrid(textgrid_path):
#     # –ü–∞—Ä—Å–∏–º —Ç–µ–∫—Å—Ç–≥—Ä–∏–¥ –∏ –≤–æ–∑–≤—Ä–∞—â–∞–µ–º —Ç–∞–π–º–∏–Ω–≥–∏ —Å–ª–æ–≤
#     # –ú–æ–∂–Ω–æ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å –±–∏–±–ª–∏–æ—Ç–µ–∫—É textgrid (pip install textgrid)
#     pass
#
# def create_ass_from_mfa(word_timings, ass_path):
#     # –°–æ–∑–¥–∞—ë–º —Å—É–±—Ç–∏—Ç—Ä—ã —Å —Ç–æ—á–Ω—ã–º–∏ —Ç–∞–π–º–∏–Ω–≥–∞–º–∏ —Å–ª–æ–≤ –∏ TikTok —Å—Ç–∏–ª–µ–º
#     pass



def extract_audio(video_path, wav_path):
    rel_video = os.path.relpath(video_path, BASE_FOLDER).replace("\\", "/")
    rel_wav   = os.path.relpath(wav_path, BASE_FOLDER).replace("\\", "/")

    cmd = [
        "ffmpeg","-y","-i", rel_video,
        "-vn","-ac","1","-ar","16000",
        rel_wav
    ]
    subprocess.run(cmd, check=True, cwd=BASE_FOLDER)


def transcribe_srt(wav_path, srt_path, model):
    print(f"üìù –¢—Ä–∞–Ω—Å–∫—Ä–∏–±–∏—Ä—É–µ–º –∞—É–¥–∏–æ ‚Üí {os.path.basename(srt_path)}")

    result = model.transcribe(wav_path, language="ru")

    def fmt(t):
        hours = int(t // 3600)
        minutes = int((t % 3600) // 60)
        seconds = int(t % 60)
        milliseconds = int((t * 1000) % 1000)
        return f"{hours:02}:{minutes:02}:{seconds:02},{milliseconds:03}"

    with open(srt_path, "w", encoding="utf-8") as f:
        for i, seg in enumerate(result["segments"], start=1):
            start = seg["start"]
            end = seg["end"]
            text = seg["text"].strip().replace("-->", "‚Üí")  # –ü—Ä–µ–¥–æ—Ç–≤—Ä–∞—â–∞–µ–º –∫–æ–Ω—Ñ–ª–∏–∫—Ç —Å SRT-—Å–∏–Ω—Ç–∞–∫—Å–∏—Å–æ–º

            f.write(f"{i}\n{fmt(start)} --> {fmt(end)}\n{text}\n\n")


def convert_srt_to_ass(srt_path, ass_path):
    print(f"üéØ –ö–æ–Ω–≤–µ—Ä—Ç–∏—Ä—É–µ–º SRT ‚Üí ASS —Å –ø–æ—è–≤–ª–µ–Ω–∏–µ–º –ø–æ –æ–¥–Ω–æ–º—É —Å–ª–æ–≤—É: {srt_path} ‚Üí {ass_path}")
    subs = pysubs2.load(srt_path, encoding="utf-8")

    style = pysubs2.SSAStyle()
    style.name = "SimpleStyle"
    style.fontname = "Arial"
    style.fontsize = 24
    style.primarycolor = pysubs2.Color(255, 255, 255)  # –±–µ–ª—ã–π
    style.alignment = 5  # —Ü–µ–Ω—Ç—Ä —ç–∫—Ä–∞–Ω–∞
    subs.styles[style.name] = style

    new_subs = pysubs2.SSAFile()

    for line in subs:
        words = line.text.strip().split()
        total_duration = line.end - line.start
        if not words:
            continue

        word_duration = total_duration // len(words)

        for i, word in enumerate(words):
            start_time = line.start + i * word_duration
            end_time = start_time + word_duration

            new_line = pysubs2.SSAEvent(
                start=start_time,
                end=end_time,
                text=word,
                style=style.name,
                layer=0,
                marginl=line.marginl,
                marginr=line.marginr,
                marginv=line.marginv,
            )
            new_subs.append(new_line)

    new_subs.styles = subs.styles
    new_subs.save(ass_path)

def convert_srt_to_ass_tiktok_style(srt_path, ass_path):
    import pysubs2

    subs = pysubs2.load(srt_path, encoding="utf-8")

    style = pysubs2.SSAStyle()
    style.name = "TikTokStyle"
    style.fontname = "Anton"
    style.fontsize = 28
    style.primarycolor = pysubs2.Color(255, 128, 0)  # –æ—Ä–∞–Ω–∂–µ–≤—ã–π
    style.outlinecolor = pysubs2.Color(0, 0, 0)      # —á–µ—Ä–Ω–∞—è –æ–±–≤–æ–¥–∫–∞
    style.backcolor = pysubs2.Color(0, 0, 0)         # —Ç–µ–Ω—å
    style.bold = True
    style.shadow = 0
    style.outline = 1
    style.alignment = 2  # —Ü–µ–Ω—Ç—Ä —Å–Ω–∏–∑—É
    subs.styles[style.name] = style

    new_lines = pysubs2.SSAFile()
    new_lines.styles = subs.styles

    for line in subs:
        words = line.text.strip().split()
        if not words:
            continue

        total_duration = line.end - line.start
        word_duration = total_duration / len(words)
        min_duration = 2.0
        current_start = line.start

        for word in words:
            duration = max(word_duration, min_duration)
            start = current_start
            end = start + duration

            # –ü—Ä–æ—Å—Ç–æ —Å–ª–æ–≤–æ –±–µ–∑ –∞–Ω–∏–º–∞—Ü–∏–π
            text = f"{{\\an5}}{word}"

            new_line = pysubs2.SSAEvent(
                start=int(start * 1000),
                end=int(end * 1000),
                text=text,
                style=style.name,
                layer=0,
                marginl=0,
                marginr=0,
                marginv=0,
            )
            new_lines.append(new_line)

            current_start = end

    new_lines.save(ass_path)


def burn_subtitles(video_in, subtitle_path, out_path):
    if subtitle_path.endswith(".srt"):
        ass_path = subtitle_path.rsplit('.', 1)[0] + ".ass"
        convert_srt_to_ass(subtitle_path, ass_path)
        subtitle_path = ass_path  # –∑–∞–º–µ–Ω—è–µ–º –ø—É—Ç—å –Ω–∞ .ass —Ñ–∞–π–ª

    rel_vid = os.path.relpath(video_in, BASE_FOLDER).replace("\\", "/")
    rel_ass = os.path.relpath(subtitle_path, BASE_FOLDER).replace("\\", "/")
    rel_out = os.path.relpath(out_path, BASE_FOLDER).replace("\\", "/")

    print(f"üî• –ü—Ä–∏–∂–∏–≥–∞–µ–º —Å—É–±—Ç–∏—Ç—Ä—ã ‚Üí {rel_out}")

    cmd = [
        "ffmpeg", "-y",
        "-fflags", "+genpts",
        "-i", rel_vid,
        "-vf", f"ass={rel_ass}",
        "-c:v", "libx264", "-crf", "23", "-preset", "medium",
        "-c:a", "copy",
        rel_out
    ]
    subprocess.run(cmd, check=True, cwd=BASE_FOLDER)



def split_segments(video_path, name, ext):

    parts_dir = os.path.join(SEGMENTS_ROOT, f"{name}_parts")
    os.makedirs(parts_dir, exist_ok=True)
    clip = VideoFileClip(video_path)

    chunks = []
    for i in tqdm(range(0, int(clip.duration), SEGMENT_TIME), desc="–†–∞–∑–¥–µ–ª–µ–Ω–∏–µ –≤–∏–¥–µ–æ –Ω–∞ —Å–µ–≥–º–µ–Ω—Ç—ã", unit="—Å–µ–≥–º–µ–Ω—Ç"):
        end = min(i + SEGMENT_TIME, clip.duration)
        sub_clip = clip.subclipped(i, end)
        chunks.append(sub_clip)

    if len(chunks) >= 2 and chunks[-1].duration < 0.9 * SEGMENT_TIME:
        chunks[-2] = concatenate_videoclips([chunks[-2], chunks[-1]])
        chunks.pop()

    for i, chunk in enumerate(chunks):
        out_file = os.path.join(parts_dir, f"{name}_part_{i:03}.mp4")
        chunk.write_videofile(out_file, codec='libx264', audio_codec='aac', temp_audiofile='temp.m4a', remove_temp=True)


def main():
    check_ffmpeg()

    top_videos = list_top_videos()
    if not top_videos:
        print("‚ùå –ù–µ—Ç –≤–µ—Ä—Ö–Ω–µ–≥–æ –≤–∏–¥–µ–æ –≤ –ø–∞–ø–∫–µ top_clips.")
        sys.exit(1)
    TOP_VIDEO = top_videos[0]
    print(f"TOP_VIDEO: {TOP_VIDEO}")

    if not os.path.isfile(TOP_VIDEO):
        print("‚ùå –ù–µ –Ω–∞–π–¥–µ–Ω –≤–µ—Ä—Ö–Ω–∏–π —Ñ–∞–π–ª:", TOP_VIDEO)
        sys.exit(1)

    bottoms = list_bottom_videos(TOP_VIDEO)
    if not bottoms:
        print("‚ùå –ù–µ—Ç –Ω–∏–∂–Ω–∏—Ö –≤–∏–¥–µ–æ –¥–ª—è –æ–±—Ä–∞–±–æ—Ç–∫–∏.")
        sys.exit(1)

    for b in bottoms:
        print(f"BOTTOM: {b}")

    if not top_videos:
        print("‚ùå –ù–µ—Ç –≤–µ—Ä—Ö–Ω–µ–≥–æ –≤–∏–¥–µ–æ –≤ –ø–∞–ø–∫–µ top_clips.")
        sys.exit(1)


    device = "cuda" if torch.cuda.is_available() else "cpu"
    print("‚ñ∫ Whisper —Ä–∞–±–æ—Ç–∞–µ—Ç –Ω–∞", device.upper())
    model = whisper.load_model("small", device=device)

    for bottom in bottoms:
        base, _ = os.path.splitext(os.path.basename(bottom))

        stacked_path  = os.path.join(STACKED_FOLDER,   base + "_stacked.mp4")
        wav_path      = os.path.join(AUDIO_FOLDER,     base + ".wav")
        srt_path      = os.path.splitext(stacked_path)[0] + ".srt"
        subtitled_path= os.path.join(SUBTITLED_FOLDER, base + "_subtitled.mp4")

        stack_loop_with_fade(TOP_VIDEO, bottom, stacked_path,BASE_FOLDER)
        extract_audio(stacked_path, wav_path)
        transcribe_srt(wav_path, srt_path, model)
        burn_subtitles(stacked_path, srt_path, subtitled_path)
        split_segments(subtitled_path, base + "_subtitled", ".mp4")

        print(f"‚úÖ –ì–æ—Ç–æ–≤–æ –¥–ª—è ¬´{base}¬ª\n")

    print("üéâ –í—Å–µ —Ñ–∞–π–ª—ã –æ–±—Ä–∞–±–æ—Ç–∞–Ω—ã!")

if __name__ == "__main__":
    main()
